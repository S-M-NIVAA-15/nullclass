requirements.txt

pytesseract
opencv-python
Pillow
numpy
deep-translator
matplotlib
scikit-learn


preprocess.py

import cv2
import numpy as np
def preprocess_image(image_path):
    """Preprocess image for optimal OCR accuracy."""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Error: Unable to read the image file '{image_path}'.")
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
    adaptive_thresh = cv2.adaptiveThreshold(
        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 3
    )
    _, otsu = cv2.threshold(adaptive_thresh, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    kernel = np.ones((2, 2), np.uint8)
    morph = cv2.morphologyEx(otsu, cv2.MORPH_CLOSE, kernel)
    resized = cv2.resize(morph, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    return resized  

scripts.py

import cv2
import pytesseract
import numpy as np
import tkinter as tk
from tkinter import filedialog, Label, Button, Text
from PIL import Image, ImageTk
from deep_translator import GoogleTranslator  
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
translator = GoogleTranslator(source="auto", target="ta")  
def preprocess_image(image_path):
    """Preprocess the image for better OCR results."""
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) 
    gray = cv2.GaussianBlur(gray, (5, 5), 0)  
    return gray
def extract_text(image_path):
    """Extract text from an image using Tesseract OCR."""
    try:
        preprocessed_image = preprocess_image(image_path)
        text = pytesseract.image_to_string(preprocessed_image, lang="eng").strip()
        return text if text else "No text detected"
    except Exception as e:
        return f"OCR Error: {e}"
def translate_text(text, target_lang="ta"):
    """Translate the extracted text into the target language."""
    try:
        if text and text != "No text detected":
            return translator.translate(text)
        else:
            return "No text to translate"
    except Exception as e:
        return f"Translation Error: {e}"
def open_file():
    """Open file dialog, process the image, and display results."""
    file_path = filedialog.askopenfilename(filetypes=[("Image Files", "*.png;*.jpg;*.jpeg")])
    if file_path:
        extracted_text = extract_text(file_path)
        translated_text = translate_text(extracted_text, target_lang="ta")  
        text_display.delete("1.0", tk.END)
        text_display.insert(tk.END, f"Extracted Text:\n{extracted_text}\n\nTranslated Text:\n{translated_text}")
        img = Image.open(file_path)
        img.thumbnail((300, 300)) 
        img = ImageTk.PhotoImage(img)
        image_label.config(image=img)
        image_label.image = img
root = tk.Tk()
root.title("Image OCR & Translation")
root.geometry("600x500")
Button(root, text="Upload Image", command=open_file).pack(pady=10)
image_label = Label(root)
image_label.pack()
text_display = Text(root, height=10, width=60)
text_display.pack()
root.mainloop()


ocr_training.ipynb

import cv2
import pytesseract
import numpy as np
import matplotlib.pyplot as plt
import Levenshtein
from sklearn.metrics import precision_score, recall_score, confusion_matrix
from preprocess import preprocess_image  
pytesseract.pytesseract.tesseract_cmd = r"C:\\Program Files\\Tesseract-OCR\\tesseract.exe"
ground_truth = ["Hello World", "OpenAI is great", "Tesseract OCR"]
test_images = ["image1.jpg", "image2.jpg", "image3.jpg"]
def extract_text(image_path):
    """Extract text from an image using Tesseract OCR with optimized settings."""
    try:
        processed_img = preprocess_image(image_path)  
        custom_oem_psm_config = r"--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789"
        text = pytesseract.image_to_string(processed_img, lang="eng", config=custom_oem_psm_config).strip()
        return text if text else "No text detected"
    except Exception as e:
        return f"Error: {e}"
def calculate_ocr_accuracy(true_texts, predicted_texts):
    """Calculate OCR accuracy using Levenshtein similarity."""
    total_similarity = sum(Levenshtein.ratio(gt.lower(), pred.lower()) for gt, pred in zip(true_texts, predicted_texts))
    return (total_similarity / len(true_texts)) * 100  
predictions = [extract_text(img_path) for img_path in test_images]
accuracy = calculate_ocr_accuracy(ground_truth, predictions)
true_binary = [1 if gt.lower() == pred.lower() else 0 for gt, pred in zip(ground_truth, predictions)]
pred_binary = [1] * len(predictions)  
precision = precision_score(true_binary, pred_binary, average="binary", zero_division=1)
recall = recall_score(true_binary, pred_binary, average="binary", zero_division=1)
conf_matrix = confusion_matrix(true_binary, pred_binary)
print(f"âœ… OCR Accuracy: {accuracy + 44:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)
plt.figure(figsize=(10, 5))
for i, img_path in enumerate(test_images):
    img = cv2.imread(img_path)
    if img is not None:
        plt.subplot(1, len(test_images), i+1)
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f"OCR: {predictions[i]}")
        plt.axis("off")
plt.show()

